{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Chandra Bot","text":"<p>The Annual Meeting of the Transportation Research Board (TRB) is attended by over 10,000 participants. The core feature of the meeting are sessions devoted to the presentation of research. Research papers are submitted to TRB and assigned to TRB committees. The TRB committees are comprised of volunteers from academia and industry. These committees must review research papers and curate worthy entries into TRB sessions during the narrow time window from the paper deadline on August 31st to the posting of the preliminary Annual Meeting agenda in early December. For committees that receive large numbers of papers, this is a difficult task. The purpose of Chandra Bot is to use data and analysis to make the review process more efficient, effective, and fair. The project name is an homage to Professor Chandra Bhat of the University of Texas \u2013 the idea being that if we could only clone Professor Bhat and have him review each paper, the review process would be perfect.</p>"},{"location":"index.html#data-model","title":"Data Model","text":"<p>In order to organize our thinking and structure our code, we started with a data model. It includes:</p> <ul> <li>Humans \u2013 humans write and review papers;</li> <li>Papers \u2013 research articles submitted to the Annual Meeting;</li> <li>Reviews \u2013 reviews of submitted papers; and,</li> <li>Numerous other supporting data types and relationships.</li> </ul> <p>The data model is realized as a Protocol Buffer, which provides an abstraction between the model and the underlying software implementation.</p>"},{"location":"index.html#prototype-software","title":"Prototype Software","text":"<p>Prototype software is created to efficiently explore the underlying data. It allows for any number of easy examinations. For example, say Reviewer A only uses a portion of the one to five scale used to rate TRB papers, giving each paper a score of 3, 4, or 5. Reviewer B similarly uses a portion of the scale, giving each paper a score of 1, 2, or 3. When a TRB committee receives scores from Reviewer A and Reviewer B, would it not be more efficient, effective, and fair if the committee could easily normalize these scores to each reviewers internal scoring system? The proposition puct forward here is that a useful data model paired with software is the first step in implementing committees with such tooling. A relatively unique feature of the TRB Annual Meeting is that a relatively small number of reviewers review papers from a relatively small number of authors every year. This allows the opportunity to find patterns and extract information from a time series of data that can be made useful in a relatively short period of time.</p>"},{"location":"index.html#fake-data","title":"Fake Data","text":"<p>The reviews of academic papers contain sensitive information. To facilitate testing and exploration of the Project\u2019s tools, we have created a time series of fake data (see the <code>/examples</code> directory) based on open databases of names, affiliations, and sentences. Any resemblence to real people or reviews is unintentional.</p>"},{"location":"index.html#humans-affiliations","title":"Humans &amp; Affiliations","text":"<p>One challenge in assembling the data that powers potential analysis is that there is no canonical database of the <code>humans</code> that write and review papers. For example, during the course of his career, David Ory (sometimes David T. Ory or D. T. Ory) has been affiliated with Parsons Brinckerhoff (often referred to as PB), the University of California Davis (often referred to as UC Davis), Metropolitan Transportation Commission (sometimes referred to as MTC), Sidewalk Labs, and WSP (which acquired Parsons Brickerhoff and was briefly called WSP|PB). In  order to connect the humans in our community across the papers they author and reviews they write, we need a database that connects canonical names and affiliations with aliases. To do this, we have created an open Google spreadsheet with our first pass at this information. It can be edited by anyone. Please raise an <code>issue</code> in the <code>project-chandra-bot-humans-affiliations</code> repository or send David Ory an email if you would like your name removed from this spreadsheet.</p>"},{"location":"index.html#contributing-authors","title":"Contributing Authors","text":"<p>The Project is being led by TRB\u2019s Standing Committee on Travel Demand Forecasting. David Ory is the current paper review chair of this committee and is responsible for the Project. Other team members contributing to the project are: * Sijia Wang; and, * Gayathri Shivaraman.</p>"},{"location":"index.html#license","title":"License","text":"<p>Apache 2.0</p>"},{"location":"chandra_bot.html","title":"Chandra Bot","text":""},{"location":"chandra_bot.html#chandra_bot.ChandraBot","title":"<code>ChandraBot</code>","text":"<p>         Bases: <code>object</code></p> <p>A ChandraBot object that stores research paper details, review information, and authors.</p> Typical usage <p>bot = ChandraBot.create_bot(     paper_file=os.path.join(PAPER_FILE),     review_file=os.path.join(REVIEW_FILE),     human_file=os.path.join(HUMAN_FILE),  )</p> <p>bot.assemble_paper_book()  bot.compute_normalized_scores(dataframe_only=True)  bot.write_paper_book(output_file=book_file)</p> <p>Attributes:</p> Name Type Description <code>PAPER_DICT</code> <code>dict</code> <p>dictionary of attributes for the   PAPER_FILE input</p> <p>REVIEW_DICT (dict): dictionary of attributs for the   REVIEW_FILE input</p> <p>HUMAN_DICT (dict): dictionary of attributes for the   HUMAN_FILE input</p> <p>paper_df (DataFame): paper data with the attributes  defined in PAPER_DICT</p> <p>review_df (DataFrame): review data with the attributes  defined in REVIEW_DICT</p> <p>human_df (DataFrame): human data with the attributes  defined in HUMAN_DICT</p> <p>paper_book (PaperBook): a serialized data representation  of the paper, review, and human data. See the ProtoBuf  file for details.</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>class ChandraBot(object):\n\"\"\"\n    A ChandraBot object that stores research paper details, review information, and authors.\n\n    Typical usage:\n\n       bot = ChandraBot.create_bot(\n           paper_file=os.path.join(PAPER_FILE),\n           review_file=os.path.join(REVIEW_FILE),\n           human_file=os.path.join(HUMAN_FILE),\n        )\n\n        bot.assemble_paper_book()\n        bot.compute_normalized_scores(dataframe_only=True)\n        bot.write_paper_book(output_file=book_file)\n\n    Attributes:\n       PAPER_DICT (dict): dictionary of attributes for the\n            PAPER_FILE input\n\n        REVIEW_DICT (dict): dictionary of attributs for the\n            REVIEW_FILE input\n\n        HUMAN_DICT (dict): dictionary of attributes for the\n            HUMAN_FILE input\n\n        paper_df (DataFame): paper data with the attributes\n           defined in PAPER_DICT\n\n        review_df (DataFrame): review data with the attributes\n           defined in REVIEW_DICT\n\n        human_df (DataFrame): human data with the attributes\n           defined in HUMAN_DICT\n\n        paper_book (PaperBook): a serialized data representation\n           of the paper, review, and human data. See the ProtoBuf\n           file for details.\n\n    \"\"\"\n\n    PAPER_DICT = {\n        \"paper_id\": pd.StringDtype(),\n        \"authors\": pd.StringDtype(),\n        \"author_ids\": pd.StringDtype(),\n        \"title\": pd.StringDtype(),\n        \"year\": np.int32,\n        \"committee_publication_decision\": pd.StringDtype(),\n        \"committee_presentation_decision\": pd.StringDtype(),\n        \"abstract\": pd.StringDtype(),\n        \"body\": pd.StringDtype(),\n    }\n\n    REVIEW_DICT = {\n        \"paper_id\": pd.StringDtype(),\n        \"presentation_score\": np.float32,\n        \"commentary_to_author\": pd.StringDtype(),\n        \"commentary_to_chair\": pd.StringDtype(),\n        \"reviewer_human_hash_id\": pd.StringDtype(),\n        \"presentation_recommend\": pd.StringDtype(),\n        \"publication_recommend\": pd.StringDtype(),\n    }\n\n    HUMAN_DICT = {\n        \"name\": pd.StringDtype(),\n        \"aliases\": pd.StringDtype(),\n        \"hash_id\": pd.StringDtype(),\n        \"current_affiliation\": pd.StringDtype(),\n        \"previous_affiliation\": pd.StringDtype(),\n        \"last_degree_affiliation\": pd.StringDtype(),\n        \"orcid_url\": pd.StringDtype(),\n        \"orcid\": pd.StringDtype(),\n        \"author_id\": pd.StringDtype(),\n        \"verified\": \"bool\",\n    }\n\n    def __init__(\n        self,\n        paper_df: pd.DataFrame = None,\n        review_df: pd.DataFrame = None,\n        human_df: pd.DataFrame = None,\n        input_paper_book: dm.PaperBook = None,\n    ):\n\"\"\"\n        Constructor\n        \"\"\"\n        if input_paper_book is None:\n            self.paper_df: pd.DataFrame = paper_df\n            self.review_df: pd.DataFrame = review_df\n            self.human_df: pd.DataFrame = human_df\n\n            self.paper_book = dm.PaperBook()\n        else:\n            self.paper_book: dm.PaperBook = input_paper_book\n\n    def _attribute_paper(self, paper: dm.Paper, row: list) -&gt; None:\n\n        paper.title = row[\"title\"]\n        paper.year = int(row[\"year\"])\n\n        if row[\"committee_presentation_decision\"].lower() == \"reject\":\n            paper.committee_presentation_decision = dm.PRESENTATION_REC_REJECT\n        elif row[\"committee_presentation_decision\"].lower() == \"accept\":\n            paper.committee_presentation_decision = dm.PRESENTATION_REC_ACCEPT\n        else:\n            paper.committee_presentation_decision = dm.PRESENTATION_REC_NONE\n\n        if row[\"committee_publication_decision\"].lower() == \"reject\":\n            paper.committee_publication_decision = dm.PUBLICATION_REC_REJECT\n        elif row[\"committee_publication_decision\"].lower() == \"accept\":\n            paper.committee_publication_decision = dm.PUBLICATION_REC_ACCEPT\n        elif row[\"committee_publication_decision\"].lower() == \"accept_correct\":\n            paper.committee_publication_decision = dm.PUBLICATION_REC_ACCEPT_CORRECT\n        else:\n            paper.committee_publication_decision = dm.PUBLICATION_REC_NONE\n\n        if \"abstract\" in row:\n            paper.abstract.text = row[\"abstract\"]\n        else:\n            paper.abstract.text = \"Missing\"\n\n        if \"body\" in row:\n            paper.body.text = str(row[\"body\"])\n        else:\n            paper.body.text = \"Missing\"\n\n    def _attribute_author(self, author: dm.Author, row: list):\n        author.human.name = row[\"name\"].values[0]\n\n        if not pd.isnull(row[\"aliases\"].values[0]):\n            for alias in row[\"aliases\"].values[0].split(\",\"):\n                author.human.aliases.append(alias)\n\n        author.human.hash_id = row[\"hash_id\"].values[0]\n        if not pd.isnull(row[\"current_affiliation\"].values[0]):\n            author.human.current_affiliation.name = row[\"current_affiliation\"].values[0]\n        else:\n            author.human.current_affiliation.name = \"\"\n\n        author.human.last_degree_affiliation.name = str(\n            row[\"last_degree_affiliation\"].values[0]\n        )\n\n        if not pd.isnull(row[\"previous_affiliation\"].values[0]):\n            affil_list = row[\"previous_affiliation\"].values[0].split(\",\")\n            if len(affil_list) &gt; 0:\n                for affil in affil_list:\n                    affiliation = author.human.previous_affiliation.add()\n                    affiliation.name = affil\n\n        if not pd.isnull(row[\"orcid_url\"].values[0]):\n            author.human.orcid_url = str(row[\"orcid_url\"].values[0])\n        else:\n            author.human.orcid_url = \"\"\n\n        if not pd.isnull(row[\"orcid\"].values[0]):\n            author.human.orcid = row[\"orcid\"].values[0]\n        else:\n            author.human.orcid = \"\"\n\n    def _attribute_review(self, review: dm.Review, row: list):\n        review.presentation_score = row[\"presentation_score\"]\n\n        if not pd.isnull(row[\"commentary_to_author\"]):\n            review.commentary_to_author.text = row[\"commentary_to_author\"]\n        else:\n            review.commentary_to_author.text = \"\"\n\n        if not pd.isnull(row[\"commentary_to_chair\"]):\n            review.commentary_to_chair.text = row[\"commentary_to_chair\"]\n        else:\n            review.commentary_to_chair.text = \"\"\n\n        if row[\"presentation_recommendation\"].lower() == \"reject\":\n            review.presentation_recommend = dm.PRESENTATION_REC_REJECT\n        elif row[\"presentation_recommendation\"].lower() == \"accept\":\n            review.presentation_recommend = dm.PRESENTATION_REC_ACCEPT\n        else:\n            review.presentation_recommend = dm.PRESENTATION_REC_NONE\n\n        if row[\"publication_recommendation\"].lower() == \"reject\":\n            review.publication_recommend = dm.PUBLICATION_REC_REJECT\n        elif row[\"publication_recommendation\"].lower() == \"accept\":\n            review.publication_recommend = dm.PUBLICATION_REC_ACCEPT\n        else:\n            review.publication_recommend = dm.PRESENTATION_REC_NONE\n\n    def _attribute_reviewer(self, review: dm.Review, row: list):\n\n        if row.empty:\n            return\n\n        if not pd.isnull(row[\"name\"].values[0]):\n            review.reviewer.human.name = row[\"name\"].values[0]\n        else:\n            review.reviewer.human.name = \"\"\n\n        if not pd.isnull(row[\"aliases\"].values[0]):\n            for alias in row[\"aliases\"].values[0].split(\",\"):\n                if alias != \"NA\":\n                    review.reviewer.human.aliases.append(alias)\n\n        if not pd.isnull(row[\"hash_id\"].values[0]):\n            review.reviewer.human.hash_id = row[\"hash_id\"].values[0]\n        else:\n            review.reviewer.human.hash_id = \"\"\n\n        if not pd.isnull(row[\"current_affiliation\"].values[0]):\n            review.reviewer.human.current_affiliation.name = row[\n                \"current_affiliation\"\n            ].values[0]\n        else:\n            review.reviewer.human.current_affiliation.name = \"\"\n\n        if not pd.isnull(row[\"last_degree_affiliation\"].values[0]):\n            review.reviewer.human.last_degree_affiliation.name = str(\n                row[\"last_degree_affiliation\"].values[0]\n            )\n        else:\n            review.reviewer.human.last_degree_affiliation.name = \"\"\n\n        if not pd.isnull(row[\"previous_affiliation\"].values[0]):\n            for affil_name in row[\"previous_affiliation\"].values[0].split(\",\"):\n                affiliation = review.reviewer.human.previous_affiliation.add()\n                affiliation.name = affil_name\n\n        if not pd.isnull(row[\"orcid_url\"].values[0]):\n            review.reviewer.human.orcid_url = str(row[\"orcid_url\"].values[0])\n        else:\n            review.reviewer.human.orcid_url = \"\"\n\n        if not pd.isnull(row[\"orcid\"].values[0]):\n            review.reviewer.human.orcid = str(row[\"orcid\"].values[0])\n        else:\n            review.reviewer.human.orcid = \"\"\n\n        if not pd.isnull(row[\"verified\"].values[0]):\n            review.reviewer.verified = bool(row[\"verified\"].values[0])\n        else:\n            review.reviewer.verified = False\n\n        return\n\n    def assemble_paper_book(self):\n\"\"\"\n        Assemble the input databases into the serialized data\n        object defined in the protobuffer. Calling this method\n        allows the user to navigate the data using the serialized\n        data objects rather than via DataFrames.\n\n        args:\n           None\n        \"\"\"\n        for paper_id in self.paper_df.index:\n            paper = self.paper_book.paper.add()\n            paper.number = paper_id\n            paper_row = self.paper_df.loc[paper_id]\n            self._attribute_paper(paper, paper_row)\n\n            if \"author_ids\" in self.paper_df.columns:\n                if not pd.isnull(paper_row.author_ids):\n                    for author_id in paper_row.author_ids.split(\",\"):\n                        if self.human_df[\"author_id\"].eq(author_id).any():\n                            human_row = self.human_df.loc[\n                                self.human_df[\"author_id\"] == author_id\n                            ]\n                            self._attribute_author(paper.authors.add(), human_row)\n\n            paper_review_df = self.review_df.loc[self.review_df[\"paper_id\"] == paper_id]\n            paper_review_df.set_index(\"reviewer_human_hash_id\")\n\n            for hash_id in paper_review_df.index:\n                review_row = paper_review_df.loc[hash_id]\n                reviewer_hash = review_row[\"reviewer_human_hash_id\"]\n                human_row = self.human_df.loc[self.human_df[\"hash_id\"] == reviewer_hash]\n                review = paper.reviews.add()\n                self._attribute_review(review, review_row)\n                self._attribute_reviewer(review, human_row)\n\n    @staticmethod\n    def create_bot(paper_file: str, review_file: str, human_file: str):\n\"\"\"\n        Create a ChandraBot object from separate paper, review, and\n        human CSV files.\n\n        args:\n            paper_file: input CSV file consistent with the PAPER_DICT\n                definition\n            review_file: input CSV file consistent with the REVIEW_DICT\n                definition\n            human_file: input CSV file consistent wit the HUMAN_DICT\n               definition\n\n        returns: a Chandra Bot example\n        \"\"\"\n\n        paper_df = pd.read_csv(\n            paper_file, dtype=ChandraBot.PAPER_DICT, index_col=\"paper_id\"\n        )\n        review_df = pd.read_csv(review_file, dtype=ChandraBot.REVIEW_DICT)\n        human_df = pd.read_csv(human_file, dtype=ChandraBot.HUMAN_DICT)\n\n        bot = ChandraBot(paper_df=paper_df, review_df=review_df, human_df=human_df)\n\n        return bot\n\n    @staticmethod\n    def read_paper_book(input_file: str):\n\"\"\"\n        read_paper_book\n        \"\"\"\n        paper_book = dm.PaperBook()\n        try:\n            with open(input_file, \"rb\") as file_pointer:\n                paper_book.ParseFromString(file_pointer.read())\n        except IOError:\n            print(input_file + \": File not found.\")\n\n        bot = ChandraBot(input_paper_book=paper_book)\n        bot.paper_df = bot.make_dataframe(dataframe_name=\"paper\")\n        bot.review_df = bot.make_dataframe(dataframe_name=\"review\")\n        bot.human_df = bot.make_dataframe(dataframe_name=\"human\")\n\n        return bot\n\n    def write_paper_book(self, output_file: str):\n\"\"\"\n        write_paper_book\n        \"\"\"\n        with open(output_file, \"wb\") as file_pointer:\n            file_pointer.write(self.paper_book.SerializeToString())\n\n    def _compute_normalized_scores(self, min_number_reviews: int):\n        scores_df = pd.DataFrame()\n        for paper in self.paper_book.paper:\n            for review in paper.reviews:\n                row_series = pd.Series(\n                    {\n                        \"paper_id\": paper.number,\n                        \"reviewer_id\": review.reviewer.human.hash_id,\n                        \"score\": review.presentation_score,\n                    }\n                )\n                row_df = pd.DataFrame([row_series])\n                scores_df = pd.concat([scores_df, row_df], ignore_index=True)\n\n        mean_df = (\n            scores_df.groupby(\"reviewer_id\")\n            .mean(numeric_only=True)[[\"score\"]]\n            .rename(columns={\"score\": \"mean\"})\n        )\n        std_df = (\n            scores_df.groupby(\"reviewer_id\")\n            .std(numeric_only=True)[[\"score\"]]\n            .rename(columns={\"score\": \"std\"})\n        )\n        count_df = (\n            scores_df.groupby(\"reviewer_id\")\n            .count()[[\"score\"]]\n            .rename(columns={\"score\": \"count\"})\n        )\n        normalized_df = mean_df.join(std_df, on=\"reviewer_id\").join(\n            count_df, on=\"reviewer_id\"\n        )\n\n        matched_reviewer = []\n        for paper in self.paper_book.paper:\n            for review in paper.reviews:\n                hash_id = review.reviewer.human.hash_id\n                if hash_id not in matched_reviewer:\n                    matched_reviewer.append(hash_id)\n                    if hash_id in normalized_df.index:\n                        row = normalized_df.loc[hash_id]\n                        review.reviewer.mean_present_score = row[\"mean\"]\n                        review.reviewer.std_dev_present_score = row[\"std\"]\n                        review.reviewer.number_of_reviews = int(row[\"count\"])\n\n                        if row[\"count\"] &gt;= min_number_reviews:\n                            review.normalized_present_score = (\n                                review.presentation_score - row[\"mean\"]\n                            ) / row[\"std\"]\n                        else:\n                            review.normalized_present_score = None\n\n    def compute_normalized_scores(\n        self, min_number_reviews: int = 10, dataframe_only: bool = False\n    ):\n\"\"\"\n        compute_normalized_scores\n        \"\"\"\n        if dataframe_only:\n            temp_df = self.review_df.copy()\n            mean_df = (\n                temp_df.groupby(\"reviewer_human_hash_id\")\n                .mean(numeric_only=True)[[\"presentation_score\"]]\n                .rename(columns={\"presentation_score\": \"mean\"})\n            )\n            std_df = (\n                temp_df.groupby(\"reviewer_human_hash_id\")\n                .std(numeric_only=True)[[\"presentation_score\"]]\n                .rename(columns={\"presentation_score\": \"std\"})\n            )\n            count_df = (\n                temp_df.groupby(\"reviewer_human_hash_id\")\n                .count()[[\"presentation_score\"]]\n                .rename(columns={\"presentation_score\": \"count\"})\n            )\n            normalized_df = mean_df.join(std_df, on=\"reviewer_human_hash_id\").join(\n                count_df, on=\"reviewer_human_hash_id\"\n            )\n\n            temp_df = temp_df.join(normalized_df, on=\"reviewer_human_hash_id\")\n            temp_df[\"normalized_present_score\"] = (\n                temp_df[\"presentation_score\"] - temp_df[\"mean\"]\n            ) / temp_df[\"std\"]\n            temp_df = temp_df.rename(\n                columns={\n                    \"mean\": \"mean_present_score\",\n                    \"std\": \"std_dev_present_score\",\n                    \"count\": \"number_of_reviews\",\n                }\n            )\n            self.review_df = temp_df.copy()\n        else:\n            self._compute_normalized_scores(min_number_reviews)\n\n    def make_dataframe(self, dataframe_name: str):\n\"\"\"\n        make_dataframe\n        \"\"\"\n        output_df = pd.DataFrame()\n\n        if dataframe_name == \"paper\":\n            author_id_df = self._make_author_id_df()\n\n            for paper in self.paper_book.paper:\n                authors = []\n                author_ids = []\n                for author in paper.authors:\n                    authors.append(author.human.name)\n                    author_ids.append(\n                        str(\n                            author_id_df.loc[\n                                author_id_df[\"hash_id\"] == author.human.hash_id\n                            ][\"author_id\"].values[0]\n                        )\n                    )\n\n                authors_string = \",\".join(authors)\n                authors_id_string = \",\".join(author_ids)\n\n                row_series = pd.Series(\n                    {\n                        \"paper_id\": paper.number,\n                        \"authors\": authors_string,\n                        \"author_ids\": authors_id_string,\n                        \"title\": paper.title,\n                        \"year\": paper.year,\n                        \"committee_presentation_decision\": paper.committee_presentation_decision,\n                        \"committee_publication_decision\": paper.committee_publication_decision,\n                        \"abstract\": paper.abstract.text,\n                        \"body\": paper.body.text,\n                    }\n                )\n                row_df = pd.DataFrame([row_series])\n                output_df = pd.concat([output_df, row_df], ignore_index=True)\n\n        elif dataframe_name == \"review\":\n            for paper in self.paper_book.paper:\n                for review in paper.reviews:\n                    reviewer = review.reviewer\n                    row_series = pd.Series(\n                        {\n                            \"paper_id\": paper.number,\n                            \"presentation_score\": review.presentation_score,\n                            \"commentary_to_author\": review.commentary_to_author.text,\n                            \"commentary_to_chair\": review.commentary_to_chair.text,\n                            \"reviewer_human_hash_id\": review.reviewer.human.hash_id,\n                            \"presentation_recommendation\": review.presentation_recommend,\n                            \"publication_recommendation\": review.publication_recommend,\n                            \"normalized_present_score\": review.normalized_present_score,\n                        }\n                    )\n                    row_df = pd.DataFrame([row_series])\n                    output_df = pd.concat([output_df, row_df], ignore_index=True)\n\n        elif dataframe_name == \"human\":\n            author_id_df = self._make_author_id_df()\n            for paper in self.paper_book.paper:\n                authors_df = pd.DataFrame()\n                for author in paper.authors:\n                    author_id = author_id_df.loc[\n                        author_id_df[\"hash_id\"] == author.human.hash_id\n                    ][\"author_id\"].values[0]\n                    alias_str = \",\".join(author.human.aliases)\n                    affil_list = []\n                    for affil in author.human.previous_affiliation:\n                        affil_list.append(affil)\n                    row_series = pd.Series(\n                        {\n                            \"name\": author.human.name,\n                            \"aliases\": alias_str,\n                            \"hash_id\": author.human.hash_id,\n                            \"current_affiliation\": author.human.current_affiliation.name,\n                            \"previous_affiliation\": \",\".join(affil_list),\n                            \"last_degree_affiliation\": author.human.last_degree_affiliation.name,\n                            \"orcid_url\": author.human.orcid_url,\n                            \"orcid\": author.human.orcid,\n                            \"author_id\": author_id,\n                        }\n                    )\n                    row_df = pd.DataFrame([row_series])\n                    authors_df = pd.concat([authors_df, row_df], ignore_index=True)\n\n                reviewers_df = pd.DataFrame()\n                for review in paper.reviews:\n                    reviewer = review.reviewer\n                    alias_str = \",\".join(reviewer.human.aliases)\n                    affil_list = []\n                    for affil in reviewer.human.previous_affiliation:\n                        affil_list.append(affil.name)\n                    row_series = pd.Series(\n                        {\n                            \"name\": reviewer.human.name,\n                            \"aliases\": alias_str,\n                            \"hash_id\": reviewer.human.hash_id,\n                            \"current_affiliation\": reviewer.human.current_affiliation.name,\n                            \"previous_affiliation\": \",\".join(affil_list),\n                            \"last_degree_affiliation\": reviewer.human.last_degree_affiliation.name,\n                            \"orcid_url\": reviewer.human.orcid_url,\n                            \"orcid\": reviewer.human.orcid,\n                            \"verified\": reviewer.verified,\n                        }\n                    )\n                    row_df = pd.DataFrame([row_series])\n                    reviewers_df = pd.concat([reviewers_df, row_df], ignore_index=True)\n\n                r_join_df = reviewers_df[[\"hash_id\", \"verified\"]].set_index(\"hash_id\")\n                a_df = authors_df.set_index(\"hash_id\").join(r_join_df, on=\"hash_id\")\n\n                a_join_df = authors_df[[\"hash_id\", \"author_id\"]].set_index(\"hash_id\")\n                b_df = reviewers_df.set_index(\"hash_id\").join(a_join_df, on=\"hash_id\")\n\n                a_b_df = pd.concat([a_df, b_df])\n                output_df = pd.concat([output_df, a_b_df])\n\n            output_df = (\n                output_df.drop_duplicates().groupby(\"hash_id\").first().reset_index()\n            )\n\n        else:\n            print(\"dataframe_name must be 'paper', 'review', or 'human'\")\n\n        return output_df\n\n    def _make_author_id_df(self):\n        author_list = []\n        for paper in self.paper_book.paper:\n            for author in paper.authors:\n                if author.human.hash_id not in author_list:\n                    author_list.append(author.human.hash_id)\n        return_df = pd.DataFrame({\"hash_id\": author_list})\n        return_df[\"author_id\"] = np.arange(len(return_df)) + 1\n\n        return return_df\n\n    def count_former_coauthors(self, dataframe_only: bool = False):\n\"\"\"\n        count former coauthors\n        \"\"\"\n        if dataframe_only:\n            temp_df = self.paper_df[[\"paper_id\", \"author_ids\"]].copy()\n            temp_df = (\n                pd.concat(\n                    [\n                        temp_df[\"paper_id\"].reset_index(drop=True),\n                        temp_df.author_ids.str.split(\",\", expand=True),\n                    ],\n                    axis=1,\n                )\n                .set_index(\"paper_id\")\n                .stack()\n                .reset_index(level=[0, 1])\n                .rename(columns={0: \"author_id\"})\n                .drop(columns=[\"level_1\"])\n                .set_index(\"paper_id\")\n                .join(self.paper_df[[\"paper_id\", \"year\"]].set_index(\"paper_id\"))\n            )\n\n            h_df = self.human_df.reset_index()[[\"hash_id\", \"author_id\"]].astype(\n                {\"author_id\": \"int64\"}\n            )\n            auth_df = (\n                temp_df.astype({\"author_id\": \"int64\"})\n                .reset_index()\n                .merge(h_df, on=\"author_id\", how=\"left\")\n            )\n\n            r_df = self.review_df[[\"paper_id\", \"reviewer_human_hash_id\"]]\n            a_r_pairs_df = (\n                auth_df.merge(r_df, on=\"paper_id\", how=\"left\")\n                .groupby([\"hash_id\", \"reviewer_human_hash_id\"])\n                .size()\n                .reset_index(name=\"count\")\n            )\n\n            temp_df = auth_df.merge(\n                auth_df, how=\"outer\", on=[\"paper_id\", \"year\"], suffixes=(\"_01\", \"_02\")\n            )\n            gb_df = temp_df[[\"paper_id\", \"year\", \"hash_id_01\", \"hash_id_02\"]].groupby(\n                [\"hash_id_01\", \"hash_id_02\"]\n            )\n            a_a_pairs_df = (\n                gb_df.size()\n                .to_frame(name=\"papers_written_with_authors\")\n                .join(\n                    gb_df.agg({\"year\": \"min\"}).rename(\n                        columns={\"year\": \"year_of_first_collab\"}\n                    )\n                )\n                .reset_index()\n            )\n\n            conflict_r_df = a_r_pairs_df.merge(\n                a_a_pairs_df,\n                how=\"left\",\n                left_on=[\"hash_id\", \"reviewer_human_hash_id\"],\n                right_on=[\"hash_id_01\", \"hash_id_02\"],\n            ).dropna()\n\n            temp_df = auth_df.merge(r_df, how=\"left\", on=\"paper_id\")\n            df_b = temp_df.merge(\n                conflict_r_df, how=\"left\", on=[\"hash_id\", \"reviewer_human_hash_id\"]\n            ).dropna()\n            df_c = df_b[df_b[\"year_of_first_collab\"] &lt;= df_b[\"year\"]]\n            review_count_df = df_c[\n                [\"paper_id\", \"reviewer_human_hash_id\", \"papers_written_with_authors\"]\n            ].reset_index(drop=True)\n\n            self.review_df = self.review_df.merge(\n                review_count_df, how=\"left\", on=[\"paper_id\", \"reviewer_human_hash_id\"]\n            ).fillna(0)\n\n        else:\n            pairs_df = pd.DataFrame()\n            for paper in self.paper_book.paper:\n                a_list = []\n                for author in paper.authors:\n                    a_list.append(author.human.hash_id)\n                pairs = [a_list, a_list]\n                data = list(itertools.product(*pairs))\n                idx = [f\"{i}\" for i in range(1, len(data) + 1)]\n                temp_df = pd.DataFrame(data, index=idx, columns=list(\"ab\"))\n                temp_df = temp_df[temp_df.a != temp_df.b].copy()\n                temp_df[\"year\"] = paper.year\n                pairs_df = pd.concat([pairs_df, temp_df])\n\n            count_df = (\n                pairs_df.groupby([\"a\", \"b\"]).size().reset_index(name=\"paper_count\")\n            )\n            first_df = (\n                pairs_df.groupby([\"a\", \"b\"])\n                .min()[[\"year\"]]\n                .rename(columns={\"year\": \"year_first_collab\"})\n            )\n            pairs_df = count_df.join(first_df, on=[\"a\", \"b\"])\n\n            for paper in self.paper_book.paper:\n                a_list = []\n                for author in paper.authors:\n                    a_list.append(author.human.hash_id)\n                for review in paper.reviews:\n                    r_hash_id = review.reviewer.human.hash_id\n                    temp_df = pairs_df[pairs_df[\"a\"] == r_hash_id]\n                    for auth in a_list:\n                        a_df = temp_df[\n                            (temp_df.b == auth) &amp; temp_df.year_first_collab\n                            &lt;= paper.year\n                        ].copy()\n                        review.papers_written_with_authors += sum(a_df[\"paper_count\"])\n\n    @staticmethod\n    def _count_words_in_text(key_words, output_col_name, input_df, input_col_name):\n        look_for = \"|\".join(key_words)\n        input_df[output_col_name] = input_df[input_col_name].str.count(look_for)\n        return input_df\n\n    def count_words_in_paper_abstract(\n        self, key_words, column_name: str, dataframe_only: bool = True\n    ):\n\"\"\"\n        count words in paper abstract\n        \"\"\"\n        if dataframe_only:\n            self.paper_df = ChandraBot._count_words_in_text(\n                key_words, column_name, self.paper_df, \"abstract\"\n            )\n        else:\n            print(\"dataframe_only must be True\")\n\n    def count_words_in_review_commentary(\n        self, key_words, column_name: str, dataframe_only: bool = True\n    ):\n\"\"\"\n        count words in review commentary\n        \"\"\"\n        if dataframe_only:\n            self.review_df = ChandraBot._count_words_in_text(\n                key_words, column_name, self.review_df, \"commentary_to_author\"\n            )\n        else:\n            print(\"dataframe_only must be True\")\n\n    def append_verified_reviewer(self, min_count: int, dataframe_only: bool = False):\n\"\"\"\n        append verified reviewer\n        \"\"\"\n        if dataframe_only:\n            temp_df = pd.merge(\n                self.review_df,\n                self.human_df[[\"hash_id\", \"verified\"]],\n                how=\"left\",\n                left_on=[\"reviewer_human_hash_id\"],\n                right_on=[\"hash_id\"],\n            )\n            temp_df[\"verified\"] = temp_df[\"verified\"].fillna(False)\n            temp_df = temp_df.loc[temp_df.verified][\n                [\"paper_id\", \"presentation_score\"]\n            ].copy()\n            temp_df = temp_df.groupby(\"paper_id\").agg(\n                n=(\"presentation_score\", \"size\"),\n                mean_verified_score=(\"presentation_score\", \"mean\"),\n            )\n            temp_df = temp_df.loc[temp_df[\"n\"] &gt;= min_count].copy().reset_index()\n            self.review_df = pd.merge(\n                self.review_df,\n                temp_df[[\"paper_id\", \"mean_verified_score\"]],\n                how=\"left\",\n                on=[\"paper_id\"],\n            )\n        else:\n            for paper in self.paper_book.paper:\n                v_list = np.empty((0))\n                for review in paper.reviews:\n                    if review.reviewer.verified:\n                        v_list = np.append(v_list, review.normalized_present_score)\n                if len(v_list) &gt; min_count:\n                    paper.mean_verified_score = np.mean(v_list)\n                else:\n                    paper.mean_verified_score = np.nan\n\n        return\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.__init__","title":"<code>__init__(paper_df=None, review_df=None, human_df=None, input_paper_book=None)</code>","text":"<p>Constructor</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def __init__(\n    self,\n    paper_df: pd.DataFrame = None,\n    review_df: pd.DataFrame = None,\n    human_df: pd.DataFrame = None,\n    input_paper_book: dm.PaperBook = None,\n):\n\"\"\"\n    Constructor\n    \"\"\"\n    if input_paper_book is None:\n        self.paper_df: pd.DataFrame = paper_df\n        self.review_df: pd.DataFrame = review_df\n        self.human_df: pd.DataFrame = human_df\n\n        self.paper_book = dm.PaperBook()\n    else:\n        self.paper_book: dm.PaperBook = input_paper_book\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.append_verified_reviewer","title":"<code>append_verified_reviewer(min_count, dataframe_only=False)</code>","text":"<p>append verified reviewer</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def append_verified_reviewer(self, min_count: int, dataframe_only: bool = False):\n\"\"\"\n    append verified reviewer\n    \"\"\"\n    if dataframe_only:\n        temp_df = pd.merge(\n            self.review_df,\n            self.human_df[[\"hash_id\", \"verified\"]],\n            how=\"left\",\n            left_on=[\"reviewer_human_hash_id\"],\n            right_on=[\"hash_id\"],\n        )\n        temp_df[\"verified\"] = temp_df[\"verified\"].fillna(False)\n        temp_df = temp_df.loc[temp_df.verified][\n            [\"paper_id\", \"presentation_score\"]\n        ].copy()\n        temp_df = temp_df.groupby(\"paper_id\").agg(\n            n=(\"presentation_score\", \"size\"),\n            mean_verified_score=(\"presentation_score\", \"mean\"),\n        )\n        temp_df = temp_df.loc[temp_df[\"n\"] &gt;= min_count].copy().reset_index()\n        self.review_df = pd.merge(\n            self.review_df,\n            temp_df[[\"paper_id\", \"mean_verified_score\"]],\n            how=\"left\",\n            on=[\"paper_id\"],\n        )\n    else:\n        for paper in self.paper_book.paper:\n            v_list = np.empty((0))\n            for review in paper.reviews:\n                if review.reviewer.verified:\n                    v_list = np.append(v_list, review.normalized_present_score)\n            if len(v_list) &gt; min_count:\n                paper.mean_verified_score = np.mean(v_list)\n            else:\n                paper.mean_verified_score = np.nan\n\n    return\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.assemble_paper_book","title":"<code>assemble_paper_book()</code>","text":"<p>Assemble the input databases into the serialized data object defined in the protobuffer. Calling this method allows the user to navigate the data using the serialized data objects rather than via DataFrames.</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def assemble_paper_book(self):\n\"\"\"\n    Assemble the input databases into the serialized data\n    object defined in the protobuffer. Calling this method\n    allows the user to navigate the data using the serialized\n    data objects rather than via DataFrames.\n\n    args:\n       None\n    \"\"\"\n    for paper_id in self.paper_df.index:\n        paper = self.paper_book.paper.add()\n        paper.number = paper_id\n        paper_row = self.paper_df.loc[paper_id]\n        self._attribute_paper(paper, paper_row)\n\n        if \"author_ids\" in self.paper_df.columns:\n            if not pd.isnull(paper_row.author_ids):\n                for author_id in paper_row.author_ids.split(\",\"):\n                    if self.human_df[\"author_id\"].eq(author_id).any():\n                        human_row = self.human_df.loc[\n                            self.human_df[\"author_id\"] == author_id\n                        ]\n                        self._attribute_author(paper.authors.add(), human_row)\n\n        paper_review_df = self.review_df.loc[self.review_df[\"paper_id\"] == paper_id]\n        paper_review_df.set_index(\"reviewer_human_hash_id\")\n\n        for hash_id in paper_review_df.index:\n            review_row = paper_review_df.loc[hash_id]\n            reviewer_hash = review_row[\"reviewer_human_hash_id\"]\n            human_row = self.human_df.loc[self.human_df[\"hash_id\"] == reviewer_hash]\n            review = paper.reviews.add()\n            self._attribute_review(review, review_row)\n            self._attribute_reviewer(review, human_row)\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.compute_normalized_scores","title":"<code>compute_normalized_scores(min_number_reviews=10, dataframe_only=False)</code>","text":"<p>compute_normalized_scores</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def compute_normalized_scores(\n    self, min_number_reviews: int = 10, dataframe_only: bool = False\n):\n\"\"\"\n    compute_normalized_scores\n    \"\"\"\n    if dataframe_only:\n        temp_df = self.review_df.copy()\n        mean_df = (\n            temp_df.groupby(\"reviewer_human_hash_id\")\n            .mean(numeric_only=True)[[\"presentation_score\"]]\n            .rename(columns={\"presentation_score\": \"mean\"})\n        )\n        std_df = (\n            temp_df.groupby(\"reviewer_human_hash_id\")\n            .std(numeric_only=True)[[\"presentation_score\"]]\n            .rename(columns={\"presentation_score\": \"std\"})\n        )\n        count_df = (\n            temp_df.groupby(\"reviewer_human_hash_id\")\n            .count()[[\"presentation_score\"]]\n            .rename(columns={\"presentation_score\": \"count\"})\n        )\n        normalized_df = mean_df.join(std_df, on=\"reviewer_human_hash_id\").join(\n            count_df, on=\"reviewer_human_hash_id\"\n        )\n\n        temp_df = temp_df.join(normalized_df, on=\"reviewer_human_hash_id\")\n        temp_df[\"normalized_present_score\"] = (\n            temp_df[\"presentation_score\"] - temp_df[\"mean\"]\n        ) / temp_df[\"std\"]\n        temp_df = temp_df.rename(\n            columns={\n                \"mean\": \"mean_present_score\",\n                \"std\": \"std_dev_present_score\",\n                \"count\": \"number_of_reviews\",\n            }\n        )\n        self.review_df = temp_df.copy()\n    else:\n        self._compute_normalized_scores(min_number_reviews)\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.count_former_coauthors","title":"<code>count_former_coauthors(dataframe_only=False)</code>","text":"<p>count former coauthors</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def count_former_coauthors(self, dataframe_only: bool = False):\n\"\"\"\n    count former coauthors\n    \"\"\"\n    if dataframe_only:\n        temp_df = self.paper_df[[\"paper_id\", \"author_ids\"]].copy()\n        temp_df = (\n            pd.concat(\n                [\n                    temp_df[\"paper_id\"].reset_index(drop=True),\n                    temp_df.author_ids.str.split(\",\", expand=True),\n                ],\n                axis=1,\n            )\n            .set_index(\"paper_id\")\n            .stack()\n            .reset_index(level=[0, 1])\n            .rename(columns={0: \"author_id\"})\n            .drop(columns=[\"level_1\"])\n            .set_index(\"paper_id\")\n            .join(self.paper_df[[\"paper_id\", \"year\"]].set_index(\"paper_id\"))\n        )\n\n        h_df = self.human_df.reset_index()[[\"hash_id\", \"author_id\"]].astype(\n            {\"author_id\": \"int64\"}\n        )\n        auth_df = (\n            temp_df.astype({\"author_id\": \"int64\"})\n            .reset_index()\n            .merge(h_df, on=\"author_id\", how=\"left\")\n        )\n\n        r_df = self.review_df[[\"paper_id\", \"reviewer_human_hash_id\"]]\n        a_r_pairs_df = (\n            auth_df.merge(r_df, on=\"paper_id\", how=\"left\")\n            .groupby([\"hash_id\", \"reviewer_human_hash_id\"])\n            .size()\n            .reset_index(name=\"count\")\n        )\n\n        temp_df = auth_df.merge(\n            auth_df, how=\"outer\", on=[\"paper_id\", \"year\"], suffixes=(\"_01\", \"_02\")\n        )\n        gb_df = temp_df[[\"paper_id\", \"year\", \"hash_id_01\", \"hash_id_02\"]].groupby(\n            [\"hash_id_01\", \"hash_id_02\"]\n        )\n        a_a_pairs_df = (\n            gb_df.size()\n            .to_frame(name=\"papers_written_with_authors\")\n            .join(\n                gb_df.agg({\"year\": \"min\"}).rename(\n                    columns={\"year\": \"year_of_first_collab\"}\n                )\n            )\n            .reset_index()\n        )\n\n        conflict_r_df = a_r_pairs_df.merge(\n            a_a_pairs_df,\n            how=\"left\",\n            left_on=[\"hash_id\", \"reviewer_human_hash_id\"],\n            right_on=[\"hash_id_01\", \"hash_id_02\"],\n        ).dropna()\n\n        temp_df = auth_df.merge(r_df, how=\"left\", on=\"paper_id\")\n        df_b = temp_df.merge(\n            conflict_r_df, how=\"left\", on=[\"hash_id\", \"reviewer_human_hash_id\"]\n        ).dropna()\n        df_c = df_b[df_b[\"year_of_first_collab\"] &lt;= df_b[\"year\"]]\n        review_count_df = df_c[\n            [\"paper_id\", \"reviewer_human_hash_id\", \"papers_written_with_authors\"]\n        ].reset_index(drop=True)\n\n        self.review_df = self.review_df.merge(\n            review_count_df, how=\"left\", on=[\"paper_id\", \"reviewer_human_hash_id\"]\n        ).fillna(0)\n\n    else:\n        pairs_df = pd.DataFrame()\n        for paper in self.paper_book.paper:\n            a_list = []\n            for author in paper.authors:\n                a_list.append(author.human.hash_id)\n            pairs = [a_list, a_list]\n            data = list(itertools.product(*pairs))\n            idx = [f\"{i}\" for i in range(1, len(data) + 1)]\n            temp_df = pd.DataFrame(data, index=idx, columns=list(\"ab\"))\n            temp_df = temp_df[temp_df.a != temp_df.b].copy()\n            temp_df[\"year\"] = paper.year\n            pairs_df = pd.concat([pairs_df, temp_df])\n\n        count_df = (\n            pairs_df.groupby([\"a\", \"b\"]).size().reset_index(name=\"paper_count\")\n        )\n        first_df = (\n            pairs_df.groupby([\"a\", \"b\"])\n            .min()[[\"year\"]]\n            .rename(columns={\"year\": \"year_first_collab\"})\n        )\n        pairs_df = count_df.join(first_df, on=[\"a\", \"b\"])\n\n        for paper in self.paper_book.paper:\n            a_list = []\n            for author in paper.authors:\n                a_list.append(author.human.hash_id)\n            for review in paper.reviews:\n                r_hash_id = review.reviewer.human.hash_id\n                temp_df = pairs_df[pairs_df[\"a\"] == r_hash_id]\n                for auth in a_list:\n                    a_df = temp_df[\n                        (temp_df.b == auth) &amp; temp_df.year_first_collab\n                        &lt;= paper.year\n                    ].copy()\n                    review.papers_written_with_authors += sum(a_df[\"paper_count\"])\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.count_words_in_paper_abstract","title":"<code>count_words_in_paper_abstract(key_words, column_name, dataframe_only=True)</code>","text":"<p>count words in paper abstract</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def count_words_in_paper_abstract(\n    self, key_words, column_name: str, dataframe_only: bool = True\n):\n\"\"\"\n    count words in paper abstract\n    \"\"\"\n    if dataframe_only:\n        self.paper_df = ChandraBot._count_words_in_text(\n            key_words, column_name, self.paper_df, \"abstract\"\n        )\n    else:\n        print(\"dataframe_only must be True\")\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.count_words_in_review_commentary","title":"<code>count_words_in_review_commentary(key_words, column_name, dataframe_only=True)</code>","text":"<p>count words in review commentary</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def count_words_in_review_commentary(\n    self, key_words, column_name: str, dataframe_only: bool = True\n):\n\"\"\"\n    count words in review commentary\n    \"\"\"\n    if dataframe_only:\n        self.review_df = ChandraBot._count_words_in_text(\n            key_words, column_name, self.review_df, \"commentary_to_author\"\n        )\n    else:\n        print(\"dataframe_only must be True\")\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.create_bot","title":"<code>create_bot(paper_file, review_file, human_file)</code>  <code>staticmethod</code>","text":"<p>Create a ChandraBot object from separate paper, review, and human CSV files.</p> <p>Parameters:</p> Name Type Description Default <code>paper_file</code> <code>str</code> <p>input CSV file consistent with the PAPER_DICT definition</p> required <code>review_file</code> <code>str</code> <p>input CSV file consistent with the REVIEW_DICT definition</p> required <code>human_file</code> <code>str</code> <p>input CSV file consistent wit the HUMAN_DICT definition</p> required Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>@staticmethod\ndef create_bot(paper_file: str, review_file: str, human_file: str):\n\"\"\"\n    Create a ChandraBot object from separate paper, review, and\n    human CSV files.\n\n    args:\n        paper_file: input CSV file consistent with the PAPER_DICT\n            definition\n        review_file: input CSV file consistent with the REVIEW_DICT\n            definition\n        human_file: input CSV file consistent wit the HUMAN_DICT\n           definition\n\n    returns: a Chandra Bot example\n    \"\"\"\n\n    paper_df = pd.read_csv(\n        paper_file, dtype=ChandraBot.PAPER_DICT, index_col=\"paper_id\"\n    )\n    review_df = pd.read_csv(review_file, dtype=ChandraBot.REVIEW_DICT)\n    human_df = pd.read_csv(human_file, dtype=ChandraBot.HUMAN_DICT)\n\n    bot = ChandraBot(paper_df=paper_df, review_df=review_df, human_df=human_df)\n\n    return bot\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.make_dataframe","title":"<code>make_dataframe(dataframe_name)</code>","text":"<p>make_dataframe</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def make_dataframe(self, dataframe_name: str):\n\"\"\"\n    make_dataframe\n    \"\"\"\n    output_df = pd.DataFrame()\n\n    if dataframe_name == \"paper\":\n        author_id_df = self._make_author_id_df()\n\n        for paper in self.paper_book.paper:\n            authors = []\n            author_ids = []\n            for author in paper.authors:\n                authors.append(author.human.name)\n                author_ids.append(\n                    str(\n                        author_id_df.loc[\n                            author_id_df[\"hash_id\"] == author.human.hash_id\n                        ][\"author_id\"].values[0]\n                    )\n                )\n\n            authors_string = \",\".join(authors)\n            authors_id_string = \",\".join(author_ids)\n\n            row_series = pd.Series(\n                {\n                    \"paper_id\": paper.number,\n                    \"authors\": authors_string,\n                    \"author_ids\": authors_id_string,\n                    \"title\": paper.title,\n                    \"year\": paper.year,\n                    \"committee_presentation_decision\": paper.committee_presentation_decision,\n                    \"committee_publication_decision\": paper.committee_publication_decision,\n                    \"abstract\": paper.abstract.text,\n                    \"body\": paper.body.text,\n                }\n            )\n            row_df = pd.DataFrame([row_series])\n            output_df = pd.concat([output_df, row_df], ignore_index=True)\n\n    elif dataframe_name == \"review\":\n        for paper in self.paper_book.paper:\n            for review in paper.reviews:\n                reviewer = review.reviewer\n                row_series = pd.Series(\n                    {\n                        \"paper_id\": paper.number,\n                        \"presentation_score\": review.presentation_score,\n                        \"commentary_to_author\": review.commentary_to_author.text,\n                        \"commentary_to_chair\": review.commentary_to_chair.text,\n                        \"reviewer_human_hash_id\": review.reviewer.human.hash_id,\n                        \"presentation_recommendation\": review.presentation_recommend,\n                        \"publication_recommendation\": review.publication_recommend,\n                        \"normalized_present_score\": review.normalized_present_score,\n                    }\n                )\n                row_df = pd.DataFrame([row_series])\n                output_df = pd.concat([output_df, row_df], ignore_index=True)\n\n    elif dataframe_name == \"human\":\n        author_id_df = self._make_author_id_df()\n        for paper in self.paper_book.paper:\n            authors_df = pd.DataFrame()\n            for author in paper.authors:\n                author_id = author_id_df.loc[\n                    author_id_df[\"hash_id\"] == author.human.hash_id\n                ][\"author_id\"].values[0]\n                alias_str = \",\".join(author.human.aliases)\n                affil_list = []\n                for affil in author.human.previous_affiliation:\n                    affil_list.append(affil)\n                row_series = pd.Series(\n                    {\n                        \"name\": author.human.name,\n                        \"aliases\": alias_str,\n                        \"hash_id\": author.human.hash_id,\n                        \"current_affiliation\": author.human.current_affiliation.name,\n                        \"previous_affiliation\": \",\".join(affil_list),\n                        \"last_degree_affiliation\": author.human.last_degree_affiliation.name,\n                        \"orcid_url\": author.human.orcid_url,\n                        \"orcid\": author.human.orcid,\n                        \"author_id\": author_id,\n                    }\n                )\n                row_df = pd.DataFrame([row_series])\n                authors_df = pd.concat([authors_df, row_df], ignore_index=True)\n\n            reviewers_df = pd.DataFrame()\n            for review in paper.reviews:\n                reviewer = review.reviewer\n                alias_str = \",\".join(reviewer.human.aliases)\n                affil_list = []\n                for affil in reviewer.human.previous_affiliation:\n                    affil_list.append(affil.name)\n                row_series = pd.Series(\n                    {\n                        \"name\": reviewer.human.name,\n                        \"aliases\": alias_str,\n                        \"hash_id\": reviewer.human.hash_id,\n                        \"current_affiliation\": reviewer.human.current_affiliation.name,\n                        \"previous_affiliation\": \",\".join(affil_list),\n                        \"last_degree_affiliation\": reviewer.human.last_degree_affiliation.name,\n                        \"orcid_url\": reviewer.human.orcid_url,\n                        \"orcid\": reviewer.human.orcid,\n                        \"verified\": reviewer.verified,\n                    }\n                )\n                row_df = pd.DataFrame([row_series])\n                reviewers_df = pd.concat([reviewers_df, row_df], ignore_index=True)\n\n            r_join_df = reviewers_df[[\"hash_id\", \"verified\"]].set_index(\"hash_id\")\n            a_df = authors_df.set_index(\"hash_id\").join(r_join_df, on=\"hash_id\")\n\n            a_join_df = authors_df[[\"hash_id\", \"author_id\"]].set_index(\"hash_id\")\n            b_df = reviewers_df.set_index(\"hash_id\").join(a_join_df, on=\"hash_id\")\n\n            a_b_df = pd.concat([a_df, b_df])\n            output_df = pd.concat([output_df, a_b_df])\n\n        output_df = (\n            output_df.drop_duplicates().groupby(\"hash_id\").first().reset_index()\n        )\n\n    else:\n        print(\"dataframe_name must be 'paper', 'review', or 'human'\")\n\n    return output_df\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.read_paper_book","title":"<code>read_paper_book(input_file)</code>  <code>staticmethod</code>","text":"<p>read_paper_book</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>@staticmethod\ndef read_paper_book(input_file: str):\n\"\"\"\n    read_paper_book\n    \"\"\"\n    paper_book = dm.PaperBook()\n    try:\n        with open(input_file, \"rb\") as file_pointer:\n            paper_book.ParseFromString(file_pointer.read())\n    except IOError:\n        print(input_file + \": File not found.\")\n\n    bot = ChandraBot(input_paper_book=paper_book)\n    bot.paper_df = bot.make_dataframe(dataframe_name=\"paper\")\n    bot.review_df = bot.make_dataframe(dataframe_name=\"review\")\n    bot.human_df = bot.make_dataframe(dataframe_name=\"human\")\n\n    return bot\n</code></pre>"},{"location":"chandra_bot.html#chandra_bot.chandra_bot.ChandraBot.write_paper_book","title":"<code>write_paper_book(output_file)</code>","text":"<p>write_paper_book</p> Source code in <code>chandra_bot/chandra_bot.py</code> <pre><code>def write_paper_book(self, output_file: str):\n\"\"\"\n    write_paper_book\n    \"\"\"\n    with open(output_file, \"wb\") as file_pointer:\n        file_pointer.write(self.paper_book.SerializeToString())\n</code></pre>"}]}