---
title: "Make Fake Data"
output: html_notebook
---

# TODO
1. Apply year after year with same humans

# Overhead
```{r overhead, include = FALSE}
packages_vector <- c("tidyverse")

need_to_install <- packages_vector[!(packages_vector %in% installed.packages()[,"Package"])]

if (length(need_to_install)) install.packages(need_to_install)

for (package in packages_vector) {
  library(package, character.only = TRUE)
}

```

# Remote I-O
```{r remote-io}
external_dir <- "../../data/external/"
interim_dir <- "../../data/interim/"

first_name_file_name <- "https://raw.githubusercontent.com/smashew/NameDatabases/master/NamesDatabases/first%20names/us.txt"

last_name_file_name <- "https://raw.githubusercontent.com/smashew/NameDatabases/master/NamesDatabases/surnames/us.txt"

article_titles_file_name <- paste0(external_dir, "random_article_titles.txt")

# see `make-english-sentence-db.Rmd
sentence_file_name <- paste0(interim_dir, "english-sentences.RDS")

# https://ope.ed.gov/dapip/#/download-data-files
university_file_name <- paste0(external_dir, "InstitutionCampus.csv")

output_file_name <- "fake_data.csv"

```

# Parameters
```{r parameters}
NUMBER_HUMANS <- 500
NUMBER_PAPERS <- 200
MAX_AUTHORS_PER_PAPER <- 7
REVIEWERS_PER_PAPER <- 5
MAX_REVIEW_LENGTH <- 20
```

article_title = A,
         article_type = B,
         required_reviewers = C,
         reviewer_number = D,
         confidential_comments = E,
         reviewer_comments_to_author = F,
         reviewer_recommendation = G,
         review_complete = H,
         editorial_status = I,
         overall_score_for_presentation = 
         reviewer_name

# Data Reads
```{r data-reads}
raw_first_names_df <- read_csv(first_name_file_name, col_names = FALSE, col_types = "c")
raw_last_names_df <- read_csv(last_name_file_name, col_names = FALSE, col_types = "c")

# titles data not in quotes
input_line <- readLines(article_titles_file_name)
raw_article_titles_df <- tibble(title = input_line)

sentence_df <- readRDS(sentence_file_name)

raw_university_df <- read_csv(university_file_name, col_types = cols(.default = col_character()))

```

# Clean Data
```{r clean-data}
first_names_df <- raw_first_names_df %>%
  rename(first = X1)

last_names_df <- raw_last_names_df %>%
  rename(last = X1)

article_titles_df <- raw_article_titles_df %>%
  mutate(length = str_length(title)) %>%
  filter(length > 4) %>%
  select(article_title = title, -length) 

university_df <- raw_university_df %>%
  select(affiliation = LocationName)
  

remove(raw_first_names_df, raw_last_names_df, raw_article_titles_df)

```

# Methods
```{r  methods}
select_first_n_random <- function(input_df, input_n) {
  
  return_df <- input_df %>%
    bind_cols(., tibble(random = runif(nrow(.), min = 0.0, max = 1.0))) %>%
    arrange(-random) %>%
    head(input_n) %>%
    select(-random)
  
  return(return_df)

}

create_universe_of_humans <- function(input_first_df, input_last_df, input_university_df, input_size) {
  
  working_first_df <- select_first_n_random(input_first_df, input_size) 
  
  working_last_df <- select_first_n_random(input_last_df, input_size)
  
  working_university_df <- select_first_n_random(input_university_df, input_size)
    
  return_df <- bind_cols(working_first_df, working_last_df, working_university_df) %>%
    mutate(human_id = paste0(first, "---", last, "---", affiliation))
  
  return(return_df)
  
}

create_papers <- function(input_humans_df, input_articles_df, input_size, input_max_authors) {
  
  working_title_df <- select_first_n_random(input_articles_df, input_size) %>%
    mutate(paper_number = row_number())
  
  number_authors_df <- tibble(authors = runif(input_size, min = 0, max = input_max_authors)) %>%
    mutate(authors = as.integer(ceiling(authors))) %>%
    mutate(paper_number = row_number())
  
  authors_df <- expand.grid(paper_number = seq(1:input_size), author_number = seq(1:input_max_authors)) %>%
    left_join(., number_authors_df, by = c("paper_number")) %>%
    filter(author_number <= authors) %>%
    select(paper_number, author_number) %>%
    arrange(paper_number, author_number)
  
  working_humans_df <- input_humans_df
  while (nrow(working_humans_df) < nrow(authors_df)) {
    working_humans_df <- bind_rows(working_humans_df, working_humans_df)
    
  }
  
  return_df <- authors_df %>%
    bind_cols(., head(working_humans_df, nrow(authors_df))) %>%
    left_join(., working_title_df, by = c("paper_number")) %>%
    select(paper_number, article_title, author_number, author_human_id = human_id)
  
  return(return_df)
  
}

create_reviews <- function(input_humans_df, input_papers_df, input_sentence_df, input_reviews_per, input_max_length){
  
  input_humans_df <- humans_df
  input_papers_df <- papers_df
  input_sentence_df <- sentence_df
  input_reviews_per <- REVIEWERS_PER_PAPER
  input_max_length <- MAX_REVIEW_LENGTH
  
  reviews_per_buffer <- input_reviews_per + 5
  
  reviewers_comments_df <- expand.grid(paper_number = seq(1:nrow(input_papers_df)),
                              reviewer_number = seq(1:reviews_per_buffer),
                              comments = seq(1:input_max_length)) %>%
    arrange(paper_number, reviewer_number, comments) %>%
    bind_cols(., select_first_n_random(sentence_df, nrow(.))) %>%
    rename(to_author = sentence) %>%
    bind_cols(., select_first_n_random(sentence_df, nrow(.))) %>%
    rename(to_chair = sentence)
  
  reviewers_df <- reviewers_comments_df %>%
    distinct(paper_number, reviewer_number)
  
  working_humans_df <- input_humans_df 
  while (nrow(working_humans_df) < nrow(reviewers_df)) {
    working_humans_df <- bind_rows(working_humans_df, working_humans_df)
  }
  
  reviewers_df <- bind_cols(reviewers_df, select_first_n_random(working_humans_df, nrow(reviewers_df))) %>%
    select(paper_number, reviewer_number, reviewer_human_id = human_id)
  
  # remove authors that are the paper
  reviewer_check_df <- reviewers_df %>%
    distinct(reviewer_human_id, paper_number) %>%
    mutate(reviewer = TRUE) %>%
    select(human_id = reviewer_human_id, paper_number, reviewer)
  
  author_check_df <- papers_df %>%
    distinct(author_human_id, paper_number) %>%
    mutate(author = TRUE) %>%
    select(human_id = author_human_id, paper_number, author)
  
  check_df <- left_join(reviewer_check_df, author_check_df, by = c("human_id", "paper_number")) %>%
    mutate(reviewer = replace_na(reviewer, FALSE)) %>%
    mutate(author = replace_na(author, FALSE)) %>%
    filter(author & reviewer) %>%
    mutate(remove = TRUE) %>%
    select(reviewer_human_id = human_id, paper_number,remove)
  
  working_df <- left_join(reviewers_df, check_df, by = c("reviewer_human_id", "paper_number")) %>%
    mutate(remove = replace_na(remove, FALSE)) %>%
    filter(!remove) %>%
    select(-remove) %>%
    bind_cols(., tibble(number_to_author = runif(nrow(.), min = 0.0, max = input_max_length))) %>%
    mutate(number_to_author = as.integer(ceiling(number_to_author))) %>%
    bind_cols(., tibble(number_to_chair = runif(nrow(.), min = 0.0, max = input_max_length))) %>%
    mutate(number_to_chair = as.integer(ceiling(number_to_chair))) %>%
    left_join(reviewers_comments_df, ., by = c("paper_number", "reviewer_number")) %>%
    filter(!is.na(reviewer_human_id))
  
  comments_to_author_df <- working_df %>%
    select(paper_number, reviewer_number, comments, to_author, reviewer_human_id, number_to_author) %>%
    filter(comments <= number_to_author) %>%
    group_by(paper_number, reviewer_human_id) %>%
    summarise(reviewer_comments_to_author = paste(to_author, collapse = " ")) %>%
    ungroup()
  
  comments_to_chair_df <- working_df %>%
    select(paper_number, reviewer_number, comments, to_chair, reviewer_human_id, number_to_chair) %>%
    filter(comments <= number_to_chair) %>%
    group_by(paper_number, reviewer_human_id) %>%
    summarise(confidential_comments = paste(to_chair, collapse = " ")) %>%
    ungroup()
  
  reviews_per_paper_df <- input_papers_df %>%
    distinct(paper_number) %>%
    bind_cols(., 
              tibble(number_of_reviews = runif(nrow(.), 
                                               min = input_reviews_per - 1, 
                                               max = input_reviews_per + 1))) %>%
    mutate(number_of_reviews = as.integer(ceiling(number_of_reviews)))
  
  return_df <- working_df %>%
    distinct(paper_number, reviewer_human_id) %>%
    group_by(paper_number) %>%
    mutate(reviewer_number = row_number()) %>%
    ungroup() %>%
    left_join(., reviews_per_paper_df, by = c("paper_number")) %>%
    filter(reviewer_number <= number_of_reviews) %>%
    left_join(., comments_to_author_df, by = c("paper_number", "reviewer_human_id")) %>%
    left_join(., comments_to_chair_df, by = c("paper_number", "reviewer_human_id"))
    
  # START HERE
  # 1. Need these variables: reviewer_recommendation, review_complete, editorial_status, overall_score_for_presentation
  # 2. add them, then clean up data frame
  # 3. apply for 20 years with same set of humans
  # 4. test, test
  # 5. ping sijia for code review
}
```

# Make Data
```{r make-data}
humans_df <- create_universe_of_humans(first_names_df, last_names_df, university_df, NUMBER_HUMANS)
papers_df <- create_papers(humans_df, article_titles_df, NUMBER_PAPERS, MAX_AUTHORS_PER_PAPER)
# reviews_df <- create_reviews(humans_df, papers_df, sentence_df, REVIEWERS_PER_PAPER, MAX_REVIEW_LENGTH)
```


